import os, sys, torch
from transformers import pipeline

try:
    from uroman import Uroman
    URO = Uroman()
except Exception as e:
    print("âš ï¸  ChÆ°a cÃ³ uroman hoáº·c lá»—i import:", e)
    print("ðŸ‘‰ Cháº¡y: pip install -U uroman  (yÃªu cáº§u Python >= 3.10)")
    sys.exit(2)

def romanize_kor(text: str) -> str:
    return URO.romanize_string(text)

print("HF_HOME:", os.environ.get("HF_HOME"))
device = 0 if torch.cuda.is_available() else -1

for model in ["facebook/mms-tts-kor", "facebook/mms-tts-vie"]:
    print("Preloading:", model)
    pipe = pipeline("text-to-speech", model=model, device=device)
    text = romanize_kor("ì•ˆë…•í•˜ì„¸ìš”.") if "kor" in model else "Xin chÃ o."
    out = pipe(text)  # táº¡o cache vÃ  kiá»ƒm tra end-to-end
    print("OK:", model, "sr=", out["sampling_rate"], "len=", len(out["audio"]))
print("Done.")
