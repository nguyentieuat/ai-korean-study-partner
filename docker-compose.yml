name: ai-korean-study-partner

x-common-env: &common_env
  HF_HOME: /models/hf
  TRANSFORMERS_CACHE: /models/hf
  TOKENIZERS_PARALLELISM: "false"
  OMP_NUM_THREADS: "4"
  OPENBLAS_NUM_THREADS: "4"
  MKL_NUM_THREADS: "4"
  NUMEXPR_NUM_THREADS: "4"

networks:
  web: {}

volumes:
  models: {}
  cache: {}
  logs: {}

services:
  # Reverse proxy (chỉ 80/443). KHÔNG map 5000–5005 ở đây.
  gateway:
    image: caddy:2
    container_name: gateway
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - logs:/var/log/caddy
    networks: [web]
    depends_on:
      - main_service

  main_service:
    build: ./ai-korean-be/main_service
    restart: always
    env_file: [.env]                # nếu cần OPENAI_API_KEY
    environment:
      <<: *common_env
      UVICORN_WORKERS: "1"
      CHAT_SERVICE_URL: http://chat_service:5001
      MFA_SERVICE_URL:  http://mfa_service:5002  
      TQG_SERVICE_URL:  http://tqg_service:5003
      TTS_SERVICE_URL:  http://tts_service:5004
      ASR_SERVICE_URL:  http://asr_service:5005
      LOG_FOLDER: /app/log/pronun
    volumes:
      - logs:/app/log
    networks: [web]
    # publish nếu muốn gọi trực tiếp không qua Caddy:
    ports:
      - "5000:5000"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:5000/health || curl -fsS http://localhost:5000/health || exit 1"]
      interval: 30s
      timeout: 5s
      start_period: 20s
      retries: 3

  chat_service:
    build: ./ai-korean-be/chat_service
    restart: always
    env_file: [.env]
    environment:
      <<: *common_env
      ASR_SERVICE_URL:  http://asr_service:5005
    networks: [web]
    ports:
      - "5001:5001"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:5001/health || curl -fsS http://localhost:5001/health || exit 1"]
      interval: 30s
      timeout: 5s
      start_period: 20s
      retries: 3

  mfa_service:
    build: ./ai-korean-be/mfa_service
    restart: always
    env_file: [.env]
    environment:
      <<: *common_env
      HF_HOME: /models/hf
      TRANSFORMERS_CACHE: /models/hf
      HF_TOKEN: ${HF_TOKEN}
      TTS_SERVICE_URL:  http://tts_service:5004

    volumes:
      - models:/models/hf 
    networks: [web]
    ports:
      - "5002:5002"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:5002/health || curl -fsS http://localhost:5002/health || exit 1"]
      interval: 30s
      timeout: 6s
      start_period: 40s
      retries: 3

  tqg_service:
    build: ./ai-korean-be/tqg_service
    restart: always
    environment:
      <<: *common_env
      STORAGE_DIR: /data/tqg
      ASR_SERVICE_URL:  http://asr_service:5005
    networks: [web]
    ports:
      - "5003:5003"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:5003/health || curl -fsS http://localhost:5003/health || exit 1"]
      interval: 30s
      timeout: 5s
      start_period: 20s
      retries: 3

  tts_service:
    build: ./ai-korean-be/tts_service
    restart: always
    environment:
      <<: *common_env
    networks: [web]
    ports:
      - "5004:5004"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:5004/health || curl -fsS http://localhost:5004/health || exit 1"]
      interval: 30s
      timeout: 6s
      start_period: 40s
      retries: 3

  asr_service:
    build: ./ai-korean-be/asr_service
    restart: always
    environment:
      <<: *common_env
      WHISPER_MODEL: "medium"
    networks: [web]
    ports:
      - "5005:5005"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:5005/health || curl -fsS http://localhost:5005/health || exit 1"]
      interval: 30s
      timeout: 5s
      start_period: 30s
      retries: 3

  frontend:
    build:
      context: ./ai-korean-fe
      args:
        VITE_API_URL: "http://35.215.129.189:5000"   # <-- phải là key: value
    restart: always
    networks: [web]
    ports:
      - "3000:80"    # nếu image FE serve bằng nginx trên cổng 80
