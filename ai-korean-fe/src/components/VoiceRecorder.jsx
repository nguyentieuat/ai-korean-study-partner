import React, { useState, useRef, useEffect } from "react";
import WaveSurfer from "wavesurfer.js";
const backendUrl = import.meta.env.VITE_API_URL;

const VoiceRecorder = ({
  conversation_id,
  onConversationId, // optional: parent cÃ³ thá»ƒ truyá»n Ä‘á»ƒ nháº­n id má»›i tá»« BE
  onComplete,
  history,
  setHistory,
  getFormattedHistoryForServer,
  voice = 1, // 1 = Nam (default theo yÃªu cáº§u), 0 = Ná»¯
  // Track
  sessionId: sessionIdProp,
  userIdHash: userIdHashProp,
  onTrackEvent,
}) => {
  const [recording, setRecording] = useState(false);
  const audioChunksRef = useRef([]);
  const mediaRecorderRef = useRef(null);
  const audioBlobRef = useRef(null);
  const waveformContainerRef = useRef(null);
  const waveSurferRef = useRef(null);
  const objectUrlRef = useRef(null);

  // === Tracking endpoint (khá»›p FastAPI /api/track/event) ===
  const TRACK_URL = `${backendUrl}/track/event`;
  // === Tracking identities ===
  const [sessionId, setSessionId] = useState(sessionIdProp || "");
  const [userIdHash, setUserIdHash] = useState(userIdHashProp || "");

  // Náº¿u cha khÃ´ng truyá»n, tá»± táº¡o id áº©n danh + sessionId cho phiÃªn hiá»‡n táº¡i
  useEffect(() => {
    if (!userIdHashProp) {
      let uid = localStorage.getItem("uid_hash");
      if (!uid) {
        uid = crypto?.randomUUID?.() || Math.random().toString(36).slice(2);
        localStorage.setItem("uid_hash", uid);
      }
      setUserIdHash(uid);
    } else {
      setUserIdHash(userIdHashProp);
    }

    if (!sessionIdProp) {
      const day = new Date().toISOString().slice(0, 10).replace(/-/g, "");
      const rand = Math.random().toString(36).slice(2, 6).toUpperCase();
      setSessionId(`S-${day}-${rand}`);
    } else {
      setSessionId(sessionIdProp);
    }
  }, [sessionIdProp, userIdHashProp]);

  async function postTrack(payload) {
    try {
      if (typeof onTrackEvent === "function") {
        // cho phÃ©p cha tá»± xá»­ lÃ½ náº¿u muá»‘n
        return onTrackEvent(payload);
      }
      const event_id =
        crypto?.randomUUID?.() || Math.random().toString(36).slice(2);
      await fetch(TRACK_URL, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ event_id, ...payload }),
        keepalive: true,
      });
    } catch {
      // nuá»‘t lá»—i Ä‘á»ƒ khÃ´ng áº£nh hÆ°á»Ÿng UX
    }
  }

  useEffect(() => {
    return () => {
      try {
        waveSurferRef.current?.destroy();
      } catch {}
      if (objectUrlRef.current) {
        URL.revokeObjectURL(objectUrlRef.current);
        objectUrlRef.current = null;
      }
    };
  }, []);

  const handleStart = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      setRecording(true);
      audioChunksRef.current = [];

      mediaRecorderRef.current = new MediaRecorder(stream);
      mediaRecorderRef.current.ondataavailable = (e) => {
        if (e.data && e.data.size > 0) audioChunksRef.current.push(e.data);
      };

      mediaRecorderRef.current.onstop = async () => {
        const blob = new Blob(audioChunksRef.current, { type: "audio/webm" });
        audioBlobRef.current = blob;

        // Waveform preview
        const audioUrl = URL.createObjectURL(blob);
        objectUrlRef.current = audioUrl;

        try {
          waveSurferRef.current?.destroy();
        } catch {}
        waveSurferRef.current = WaveSurfer.create({
          container: waveformContainerRef.current,
          height: 60,
          waveColor: "violet",
          progressColor: "purple",
        });
        waveSurferRef.current.load(audioUrl);

        // User voice placeholder
        const userVoiceMsgTemp = {
          role: "user",
          transcript: "â³ Äang nháº­n diá»‡n giá»ng nÃ³i...",
          waitingReply: true,
          id: Date.now(),
          isVoice: true,
        };
        setHistory((prev) => [...prev, userVoiceMsgTemp]);

        // --- 1) TRANSCRIBE ---
        const file = new File([blob], "recording.webm", { type: "audio/webm" });
        const formData = new FormData();
        formData.append("audio", file);

        try {
          const res1 = await fetch(`${backendUrl}/transcribe`, {
            method: "POST",
            body: formData,
          });
          const data1 = await res1.json();
          if (!res1.ok) throw new Error(data1?.error || "ASR error");

          const transcript = data1?.transcript || "";
          const audio_url_goc = data1?.audio_url_goc || ""; // data URL base64 tá»« BE

          // bá» placeholder user voice temp
          setHistory((prev) =>
            prev.filter((m) => m.id !== userVoiceMsgTemp.id)
          );

          // User message thá»±c sá»±
          const userMessage = {
            role: "user",
            transcript,
            audioUrl: audio_url_goc, // FE cÃ³ thá»ƒ play báº±ng <audio src={dataURL} />
          };

          // --- 2) ONCOMPLETE: táº¡o AI placeholder & gá»i talking ---
          onComplete(async (updateAiMessage) => {
            try {
              const aiPlaceholder = {
                role: "ai",
                reply: "â³ Äang pháº£n há»“i...",
                typing: true,
                id: Date.now(),
              };
              setHistory((prev) => [...prev, userMessage, aiPlaceholder]);

              const formattedHistory = getFormattedHistoryForServer([
                ...history,
                userMessage,
              ]);

              const payload = {
                transcript,
                history: formattedHistory,
                voice, // gá»­i giá»ng (0/1)
                ...(conversation_id ? { conversation_id } : {}),
              };

              // === Ä‘o latency FE cho voice chat_turn
              const t0 = performance.now();

              const res2 = await fetch(
                `${backendUrl}/korean-speaking-talking`,
                {
                  method: "POST",
                  headers: { "Content-Type": "application/json" },
                  body: JSON.stringify(payload),
                }
              );
              const data2 = await res2.json();

              const latencyMs = Math.round(performance.now() - t0);

              // náº¿u láº§n Ä‘áº§u chÆ°a cÃ³ conversation_id â†’ nháº­n tá»« BE
              if (
                !conversation_id &&
                data2?.conversation_id &&
                typeof onConversationId === "function"
              ) {
                onConversationId(data2.conversation_id);
              }

              updateAiMessage({
                role: "ai",
                replyTTS: data2.ai_reply_tts || "",
                aiVoiceUrl: data2.tts_audio_url || "",
                highlighted: data2.highlighted || "",
                typing: false,
              });

              // === TRACK: chat_turn (voice)
              postTrack({
                user_id_hash: userIdHash,
                session_id: sessionId,
                event_type: "chat_turn",
                duration_ms: latencyMs,
                meta: { mode: "voice" },
              });
            } catch (error) {
              console.error("Lá»—i khi láº¥y pháº£n há»“i AI:", error);
              updateAiMessage({
                role: "ai",
                replyTTS: "âŒ Lá»—i pháº£n há»“i tá»« AI.",
                typing: false,
              });

              // (tuá»³ chá»n) log lá»—i cÅ©ng báº±ng chat_turn vá»›i cá» error
              const latencyMsErr = 0; // khÃ´ng Ä‘o Ä‘Æ°á»£c sau exception? Ä‘á»ƒ 0 hoáº·c tá»± lÆ°u láº§n gáº§n nháº¥t
              postTrack({
                user_id_hash: userIdHash,
                session_id: sessionId,
                event_type: "chat_turn",
                duration_ms: latencyMsErr,
                meta: { mode: "voice", error: true },
              });
            }
          });
        } catch (err) {
          // bá» placeholder náº¿u transcribe lá»—i
          setHistory((prev) =>
            prev.filter((m) => m.id !== userVoiceMsgTemp.id)
          );
          console.error("Lá»—i xá»­ lÃ½ audio:", err);
          // Ä‘áº©y má»™t tin lá»—i nháº¹ (tuá»³ chá»n)
          setHistory((prev) => [
            ...prev,
            {
              role: "ai",
              reply: "âš ï¸ KhÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c giá»ng nÃ³i.",
              typing: false,
            },
          ]);
        }
      };

      mediaRecorderRef.current.start();
    } catch (error) {
      console.error("KhÃ´ng thá»ƒ truy cáº­p microphone:", error);
    }
  };

  const handleStop = () => {
    setRecording(false);
    try {
      mediaRecorderRef.current?.stop();
      // dá»«ng tracks Ä‘á»ƒ nháº£ mic
      mediaRecorderRef.current?.stream?.getTracks()?.forEach((t) => t.stop());
    } catch {}
  };

  return (
    <div>
      <button onClick={recording ? handleStop : handleStart}>
        {recording ? "â¹ Dá»«ng ghi Ã¢m" : "ğŸ™ Báº¯t Ä‘áº§u ghi Ã¢m"}
      </button>
      <div ref={waveformContainerRef} style={{ marginTop: 10 }} />
    </div>
  );
};

export default VoiceRecorder;
